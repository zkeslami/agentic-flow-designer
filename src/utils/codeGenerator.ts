import type { AgentNode, GeneratedCode } from '../types';
import type { Edge } from '@xyflow/react';
import { nodeConfigs } from './nodeConfig';

// Generate Python code from the visual flow
export function generatePythonCode(nodes: AgentNode[], edges: Edge[]): GeneratedCode {
  const warnings: string[] = [];
  let canRoundTrip = true;

  // Build adjacency list
  const adjacency: Record<string, string[]> = {};
  edges.forEach((edge) => {
    if (!adjacency[edge.source]) {
      adjacency[edge.source] = [];
    }
    adjacency[edge.source].push(edge.target);
  });

  // Generate imports
  const imports = generateImports(nodes);

  // Generate node definitions
  const nodeDefinitions = nodes.map((node) => generateNodeDefinition(node, warnings)).join('\n\n');

  // Check for code overrides that break round-trip
  nodes.forEach((node) => {
    if (node.data.hasCodeOverride) {
      canRoundTrip = false;
      warnings.push(`Node "${node.data.label}" has code overrides that may not round-trip to visual`);
    }
  });

  const python = `"""
Agentic Workflow - Generated by Flow Designer
This code is auto-generated and can be edited directly.
Round-trip compatible: ${canRoundTrip ? 'Yes' : 'No (see warnings)'}
"""

${imports}

# ============================================
# Node Definitions
# ============================================

${nodeDefinitions}

# ============================================
# Workflow Definition
# ============================================

class AgentWorkflow:
    """
    Main workflow orchestrator.
    Connects all nodes and manages execution flow.
    """

    def __init__(self):
        self.nodes = {
${nodes.map((n) => `            "${n.id}": ${toSnakeCase(n.data.label)}Node(),`).join('\n')}
        }

    async def run(self, input_data: dict) -> dict:
        """Execute the workflow with the given input."""
        context = {"input": input_data, "results": {}}

${generateExecutionFlow(nodes, edges)}

        return context["results"]


# ============================================
# Main Entry Point
# ============================================

workflow = AgentWorkflow()

async def main():
    result = await workflow.run({"query": "Hello, world!"})
    print(result)

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
`;

  // Generate JSON representation
  const json = JSON.stringify(
    {
      version: '1.0',
      metadata: {
        generatedAt: new Date().toISOString(),
        canRoundTrip,
      },
      nodes: nodes.map((n) => ({
        id: n.id,
        type: n.data.type,
        label: n.data.label,
        position: n.position,
        config: n.data.config,
        hasCodeOverride: n.data.hasCodeOverride || false,
        codeOverride: n.data.codeOverride,
      })),
      edges: edges.map((e) => ({
        id: e.id,
        source: e.source,
        target: e.target,
      })),
    },
    null,
    2
  );

  return { python, json, canRoundTrip, warnings };
}

function generateImports(nodes: AgentNode[]): string {
  const imports = new Set<string>();
  imports.add('from typing import Any, Dict, Optional');
  imports.add('from dataclasses import dataclass');
  imports.add('import asyncio');

  nodes.forEach((node) => {
    switch (node.data.type) {
      case 'retrieval':
        imports.add('from langchain.vectorstores import VectorStore');
        imports.add('from langchain.embeddings import OpenAIEmbeddings');
        break;
      case 'llm':
        imports.add('from langchain.llms import OpenAI, Anthropic');
        imports.add('from langchain.prompts import PromptTemplate');
        break;
      case 'toolUse':
        imports.add('from langchain.tools import Tool');
        imports.add('from langchain.agents import AgentExecutor');
        break;
      case 'planner':
        imports.add('from langchain.agents import create_react_agent');
        imports.add('from langchain.memory import ConversationBufferMemory');
        break;
      case 'extraction':
        imports.add('from pydantic import BaseModel, Field');
        imports.add('from langchain.output_parsers import PydanticOutputParser');
        break;
      case 'memory':
        imports.add('from langchain.memory import ConversationBufferMemory');
        break;
      case 'humanInLoop':
        imports.add('# Human-in-loop requires external approval service');
        break;
    }
  });

  return Array.from(imports).join('\n');
}

function generateNodeDefinition(node: AgentNode, warnings: string[]): string {
  const config = node.data.config;
  const nodeConfig = nodeConfigs[node.data.type];
  const className = toPascalCase(node.data.label);

  // If there's a code override, use it (but warn about round-trip)
  if (node.data.hasCodeOverride && node.data.codeOverride) {
    return `# Custom code for ${node.data.label} (code override - may not round-trip)
${node.data.codeOverride}`;
  }

  switch (node.data.type) {
    case 'trigger':
      return `@dataclass
class ${className}Node:
    """${nodeConfig.description}"""
    trigger_type: str = "${config.triggerType || 'manual'}"

    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        # Trigger node - passes input through
        return context["input"]`;

    case 'retrieval':
      return `@dataclass
class ${className}Node:
    """${nodeConfig.description}"""
    grounding_mode: str = "${config.groundingMode || 'strict'}"
    max_results: int = ${config.maxResults || 5}
    freshness_window: str = "${config.freshnessWindow || '7d'}"

    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        query = context.get("input", {}).get("query", "")

        # TODO: Initialize your vector store
        # vectorstore = VectorStore(...)
        # results = await vectorstore.similarity_search(query, k=self.max_results)

        results = []  # Placeholder

        return {
            "sources": results,
            "grounding_mode": self.grounding_mode,
            "query": query
        }`;

    case 'llm':
      return `@dataclass
class ${className}Node:
    """${nodeConfig.description}"""
    model: str = "${config.model || 'gpt-4'}"
    temperature: float = ${config.temperature || 0.7}
    max_tokens: int = ${config.maxTokens || 1000}
    system_prompt: str = """${(config.systemPrompt as string || '').replace(/"/g, '\\"')}"""
    user_prompt: str = """${(config.prompt as string || '').replace(/"/g, '\\"')}"""

    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        # Format prompt with context
        formatted_prompt = self.user_prompt
        for key, value in context.get("results", {}).items():
            formatted_prompt = formatted_prompt.replace(f"{{{{{key}}}}}", str(value))

        # TODO: Initialize your LLM
        # llm = OpenAI(model=self.model, temperature=self.temperature)
        # response = await llm.agenerate([formatted_prompt])

        response = "LLM response placeholder"  # Placeholder

        return {"response": response}`;

    case 'toolUse':
      return `@dataclass
class ${className}Node:
    """${nodeConfig.description}"""
    retry_policy: str = "${config.retryPolicy || 'exponential'}"
    max_retries: int = ${config.maxRetries || 3}

    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        # Define available tools
        tools = []  # TODO: Add your tools

        # Execute with retry logic
        for attempt in range(self.max_retries):
            try:
                # tool_result = await execute_tool(context)
                return {"tool_result": "placeholder"}
            except Exception as e:
                if attempt == self.max_retries - 1:
                    raise
                await asyncio.sleep(2 ** attempt)  # Exponential backoff

        return {"error": "Max retries exceeded"}`;

    case 'planner':
      return `@dataclass
class ${className}Node:
    """${nodeConfig.description}"""
    objective: str = """${(config.objective as string || '').replace(/"/g, '\\"')}"""
    max_steps: int = ${config.maxSteps || 10}
    checkpoints_enabled: bool = ${config.checkpoints ? 'True' : 'False'}

    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        plan = []

        # Generate plan based on objective
        # TODO: Implement planning logic

        results = []
        for step_num, step in enumerate(plan[:self.max_steps]):
            if self.checkpoints_enabled:
                # Save checkpoint
                pass
            # Execute step
            results.append({"step": step_num, "result": "placeholder"})

        return {"plan": plan, "results": results}`;

    case 'extraction':
      return `@dataclass
class ${className}Node:
    """${nodeConfig.description}"""
    precision_mode: str = "${config.precisionMode || 'balanced'}"
    validate_output: bool = ${config.validateOutput ? 'True' : 'False'}
    schema: Dict[str, Any] = None

    def __post_init__(self):
        self.schema = ${JSON.stringify(config.schema || {})}

    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        input_text = str(context.get("input", ""))

        # TODO: Implement extraction logic using schema
        # parser = PydanticOutputParser(pydantic_object=YourModel)

        extracted = {}  # Placeholder

        if self.validate_output:
            # Validate against schema
            pass

        return {"extracted": extracted}`;

    case 'triage':
      return `@dataclass
class ${className}Node:
    """${nodeConfig.description}"""
    confidence_threshold: float = ${config.confidenceThreshold || 0.8}
    escalation_route: str = "${config.escalationRoute || ''}"
    categories: list = None

    def __post_init__(self):
        self.categories = ${JSON.stringify((config.categories as string || '').split('\n').filter(Boolean))}

    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        input_data = context.get("input", {})

        # TODO: Implement classification logic
        classification = "unknown"
        confidence = 0.0

        if confidence < self.confidence_threshold:
            return {"route": self.escalation_route, "needs_review": True}

        return {"classification": classification, "confidence": confidence}`;

    case 'memory':
      return `@dataclass
class ${className}Node:
    """${nodeConfig.description}"""
    memory_scope: str = "${config.memoryScope || 'user'}"
    retention_days: int = ${config.retentionDays || 30}

    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        # TODO: Implement memory storage/retrieval
        # memory = ConversationBufferMemory()

        return {"memory_updated": True}`;

    case 'humanInLoop':
      return `@dataclass
class ${className}Node:
    """${nodeConfig.description}"""
    approval_type: str = "${config.approvalType || 'single'}"
    sla_minutes: int = ${config.slaMinutes || 60}
    escalation_path: str = "${config.escalationPath || ''}"

    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        # This requires external approval service integration
        # TODO: Implement approval workflow

        # Placeholder: auto-approve for testing
        return {"approved": True, "approver": "auto"}`;

    case 'evaluation':
      return `@dataclass
class ${className}Node:
    """${nodeConfig.description}"""
    dataset: str = "${config.dataset || ''}"
    threshold: float = ${config.threshold || 0.9}

    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        # TODO: Implement evaluation logic

        return {"score": 0.95, "passed": True}`;

    case 'output':
      return `@dataclass
class ${className}Node:
    """${nodeConfig.description}"""
    output_format: str = "${config.outputFormat || 'json'}"

    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        results = context.get("results", {})

        if self.output_format == "json":
            return results
        elif self.output_format == "text":
            return {"text": str(results)}
        else:
            return results`;

    default:
      warnings.push(`Unknown node type: ${node.data.type}`);
      return `# Unknown node type: ${node.data.type}`;
  }
}

function generateExecutionFlow(nodes: AgentNode[], edges: Edge[]): string {
  // Simple topological execution
  const lines: string[] = [];
  const visited = new Set<string>();

  // Build adjacency and find roots
  const inDegree: Record<string, number> = {};
  const adj: Record<string, string[]> = {};

  nodes.forEach((n) => {
    inDegree[n.id] = 0;
    adj[n.id] = [];
  });

  edges.forEach((e) => {
    adj[e.source].push(e.target);
    inDegree[e.target] = (inDegree[e.target] || 0) + 1;
  });

  // Find roots (nodes with no incoming edges)
  const queue = nodes.filter((n) => inDegree[n.id] === 0).map((n) => n.id);

  while (queue.length > 0) {
    const nodeId = queue.shift()!;
    if (visited.has(nodeId)) continue;
    visited.add(nodeId);

    const node = nodes.find((n) => n.id === nodeId);
    if (!node) continue;

    const varName = toSnakeCase(node.data.label);
    lines.push(`        # Execute: ${node.data.label}`);
    lines.push(`        context["results"]["${varName}"] = await self.nodes["${nodeId}"].execute(context)`);
    lines.push('');

    adj[nodeId].forEach((target) => {
      inDegree[target]--;
      if (inDegree[target] === 0) {
        queue.push(target);
      }
    });
  }

  return lines.join('\n');
}

function toSnakeCase(str: string): string {
  return str
    .replace(/([A-Z])/g, '_$1')
    .toLowerCase()
    .replace(/^_/, '')
    .replace(/[^a-z0-9_]/g, '_')
    .replace(/_+/g, '_');
}

function toPascalCase(str: string): string {
  return str
    .split(/[^a-zA-Z0-9]/)
    .map((word) => word.charAt(0).toUpperCase() + word.slice(1).toLowerCase())
    .join('');
}

// Parse Python code back to flow (limited - only works with generated code)
export function parseCodeToFlow(code: string): { nodes: Partial<AgentNode>[]; edges: Edge[] } | null {
  // This is a simplified parser - full bi-directional would require AST parsing
  try {
    // Look for JSON comment block if present
    const jsonMatch = code.match(/"""[\s\S]*?Flow Definition:[\s\S]*?({[\s\S]*?})[\s\S]*?"""/);
    if (jsonMatch) {
      return JSON.parse(jsonMatch[1]);
    }

    // Otherwise, cannot reliably parse custom code
    return null;
  } catch {
    return null;
  }
}
